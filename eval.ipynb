{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmPZ2fVGvCqW"
   },
   "source": [
    "This notebook is for the first task: evaluate models on SPair-71k using PCK as metric.\\\n",
    "This file is intended to be run on Colab, not locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 21211,
     "status": "ok",
     "timestamp": 1764945870033,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "Yduy5K_ZU_nV",
    "outputId": "101220f8-4752-4ec6-c02b-752c88131c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Semantic-Correspondence'...\n",
      "remote: Enumerating objects: 87, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
      "remote: Total 87 (delta 25), reused 73 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (87/87), 4.66 MiB | 11.06 MiB/s, done.\n",
      "Resolving deltas: 100% (25/25), done.\n",
      "Cloning into 'dinov3'...\n",
      "remote: Enumerating objects: 538, done.\u001b[K\n",
      "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
      "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
      "remote: Total 538 (delta 201), reused 99 (delta 99), pack-reused 175 (from 1)\u001b[K\n",
      "Receiving objects: 100% (538/538), 9.88 MiB | 19.02 MiB/s, done.\n",
      "Resolving deltas: 100% (223/223), done.\n",
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-8tptbpqq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-8tptbpqq\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: segment_anything\n",
      "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=ddd9a46a278cd241cfe37a8276af37e0d74c1e3128c78147ec22dcc8d2c7f3cf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sw3h3y9s/wheels/29/82/ff/04e2be9805a1cb48bec0b85b5a6da6b63f647645750a0e42d4\n",
      "Successfully built segment_anything\n",
      "Installing collected packages: segment_anything\n",
      "Successfully installed segment_anything-1.0\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r Semantic-Correspondence/requirements.txt (line 2)) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r Semantic-Correspondence/requirements.txt (line 3)) (0.24.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r Semantic-Correspondence/requirements.txt (line 11)) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r Semantic-Correspondence/requirements.txt (line 13)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r Semantic-Correspondence/requirements.txt (line 16)) (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r Semantic-Correspondence/requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 13)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r Semantic-Correspondence/requirements.txt (line 16)) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 13)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r Semantic-Correspondence/requirements.txt (line 2)) (3.0.3)\n",
      "Collecting ftfy (from -r dinov3/requirements.txt (line 1))\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 3)) (2025.11.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 4)) (1.6.1)\n",
      "Collecting submitit (from -r dinov3/requirements.txt (line 5))\n",
      "  Downloading submitit-1.5.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 7)) (2.9.0+cu126)\n",
      "Collecting torchmetrics (from -r dinov3/requirements.txt (line 8))\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r dinov3/requirements.txt (line 9)) (0.24.0+cu126)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->-r dinov3/requirements.txt (line 1)) (0.2.14)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r dinov3/requirements.txt (line 2)) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r dinov3/requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r dinov3/requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r dinov3/requirements.txt (line 4)) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r dinov3/requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r dinov3/requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from submitit->-r dinov3/requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from submitit->-r dinov3/requirements.txt (line 5)) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r dinov3/requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->-r dinov3/requirements.txt (line 8)) (25.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics->-r dinov3/requirements.txt (line 8))\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r dinov3/requirements.txt (line 9)) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r dinov3/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r dinov3/requirements.txt (line 7)) (3.0.3)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading submitit-1.5.3-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: submitit, lightning-utilities, ftfy, torchmetrics\n",
      "Successfully installed ftfy-6.3.1 lightning-utilities-0.15.2 submitit-1.5.3 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "# Repositories\n",
    "!git clone https://github.com/Luffy65/Semantic-Correspondence.git # Clone repo\n",
    "!git clone https://github.com/facebookresearch/dinov3.git # DINOv3\n",
    "!pip install git+https://github.com/facebookresearch/segment-anything.git # SAM\n",
    "\n",
    "# Install requirements\n",
    "!pip install -r Semantic-Correspondence/requirements.txt\n",
    "!pip install -r dinov3/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764948416129,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "lw8IdqfmaLiJ"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import cv2\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35488,
     "status": "ok",
     "timestamp": 1764945912525,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "3Tc2aF3huiaP",
    "outputId": "509e7d3d-a3fb-4502-c108-f60db8e7625b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Extracting /content/drive/MyDrive/AML-PROJECT-DATA/dataset/SPair-71k.tar.gz to local VM...\n",
      "Done! Data is ready at: /content/data\n"
     ]
    }
   ],
   "source": [
    "# Connect to Google Drive, load and unzip data\n",
    "# 1. Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define Paths\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/AML-PROJECT-DATA/'\n",
    "DATASET_ROOT = os.path.join(DRIVE_ROOT, 'dataset/')\n",
    "DATASET_ARCHIVE = os.path.join(DATASET_ROOT, 'SPair-71k.tar.gz')\n",
    "\n",
    "LOCAL_DATA_DIR = '/content/data'\n",
    "\n",
    "# 3. Copy and Extract\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    print(f\"Extracting {DATASET_ARCHIVE} to local VM...\")\n",
    "    os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
    "    shutil.unpack_archive(DATASET_ARCHIVE, LOCAL_DATA_DIR, format='gztar')\n",
    "    print(\"Done! Data is ready at:\", LOCAL_DATA_DIR)\n",
    "else:\n",
    "    print(\"Data already loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 13391,
     "status": "ok",
     "timestamp": 1764950746389,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "jex_u4HHQfqH",
    "outputId": "93098422-735b-42fa-a365-402ca004ded3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the 3 foundation models\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "CHECKPOINTS_ROOT = os.path.join(DRIVE_ROOT, 'checkpoints/')\n",
    "SAM_WEIGHTS_PATH = os.path.join(CHECKPOINTS_ROOT, 'sam_vit_b_01ec64.pth')\n",
    "DINOV3_WEIGHTS_PATH = os.path.join(CHECKPOINTS_ROOT, 'dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth')\n",
    "DINOV3_REPO_DIR = \"dinov3\"\n",
    "\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=SAM_WEIGHTS_PATH)\n",
    "sampredictor = SamPredictor(sam)\n",
    "\n",
    "dinov2_vitb14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "dinov3_vitb16 = torch.hub.load(DINOV3_REPO_DIR, 'dinov3_vitb16', source='local', weights=DINOV3_WEIGHTS_PATH) # DINOv3 ViT model pretrained on web images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "dvuke95VVxip"
   },
   "outputs": [],
   "source": [
    "# Exploration: see if the models work\n",
    "\n",
    "# SAM (it works). multimask_output=True outputs 3 masks; multimask_output=False outputs 1 mask. Maybe 3 is better.\n",
    "\"\"\"\n",
    "# print(sam) # prints the layers\n",
    "\n",
    "AEROPLANES_DIR = os.path.join(LOCAL_DATA_DIR, 'SPair-71k/JPEGImages/aeroplane')\n",
    "\n",
    "for image_name in os.listdir(AEROPLANES_DIR):\n",
    "    image_path = os.path.join(AEROPLANES_DIR, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert BGR to RGB for displaying with matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    print(\"Original Image:\")\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    sampredictor.set_image(image_rgb) # Set RGB image for prediction\n",
    "    masks, scores, logits = sampredictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=None,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "\n",
    "    # Display all predicted masks\n",
    "    if masks is not None and len(masks) > 0:\n",
    "        for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "            # Overlay the mask on the original image (optional, for better visualization)\n",
    "            segmented_image = image_rgb.copy()\n",
    "            alpha = 0.5\n",
    "            color = (255, 0, 0) # Red color for the mask\n",
    "            for c in range(3):\n",
    "                segmented_image[:, :, c] = segmented_image[:, :, c] * (1 - alpha) + mask * alpha * color[c]\n",
    "\n",
    "            print(f\"Segmented Image (Mask {i}, Score: {score:.4f}):\")\n",
    "            plt.imshow(segmented_image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No masks found for this image.\")\n",
    "\n",
    "    # Break after the first image for demonstration purposes\n",
    "    break\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52dJSft4SIKE"
   },
   "outputs": [],
   "source": [
    "# --- Extract features from the foundation models ---\n",
    "\n",
    "def extract_dino_features(model, img_tensor):\n",
    "    \"\"\"\n",
    "    Extracts dense features from DINO-like models (ViT).\n",
    "    Returns: (1, Feature_Dim, H_grid, W_grid)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if hasattr(model, 'forward_features'):\n",
    "            out = model.forward_features(img_tensor)\n",
    "            # Handle dictionary output (common in DINOv2/v3)\n",
    "            if isinstance(out, dict):\n",
    "                patch_tokens = out.get(\"x_norm_patchtokens\", out.get(\"x_norm_patch_tokens\"))\n",
    "            else:\n",
    "                patch_tokens = out\n",
    "\n",
    "            if patch_tokens is None:\n",
    "                raise ValueError(f\"Could not find patch tokens. Keys: {out.keys() if isinstance(out, dict) else 'N/A'}\")\n",
    "\n",
    "            # Reshape: (B, N, D) -> (B, D, H, W)\n",
    "            B, N, D = patch_tokens.shape\n",
    "            grid_size = int(np.sqrt(N))\n",
    "            feature_map = patch_tokens.permute(0, 2, 1).reshape(B, D, grid_size, grid_size)\n",
    "            return feature_map\n",
    "    return None\n",
    "\n",
    "def extract_sam_features(predictor, image_np):\n",
    "    \"\"\"\n",
    "    Extracts features using SAM Image Encoder.\n",
    "    \"\"\"\n",
    "    predictor.set_image(image_np) # Expects HxWxC uint8\n",
    "    with torch.no_grad():\n",
    "        # Get the image embedding (1, 256, 64, 64)\n",
    "        features = predictor.get_image_embedding()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1764951192069,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "hoHJ5O3qvIBS"
   },
   "outputs": [],
   "source": [
    "# --- Main Evaluation Function ---\n",
    "\n",
    "def computePCKatT(model, dataset_root, thresholds=[0.05, 0.1, 0.2], img_size=(224, 224)):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    is_sam = False\n",
    "    if \"SamPredictor\" in str(type(model)):\n",
    "        is_sam = True\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    # Base Paths\n",
    "    pair_ann_root = os.path.join(dataset_root, 'SPair-71k/PairAnnotation')\n",
    "    image_dir = os.path.join(dataset_root, 'SPair-71k/JPEGImages')\n",
    "\n",
    "    # Find Annotation Files (Focus on 'test' split)\n",
    "    search_paths = [os.path.join(pair_ann_root, 'test')]\n",
    "    pair_files = []\n",
    "\n",
    "    print(\"Searching for annotation files...\")\n",
    "    for path in search_paths:\n",
    "        if os.path.isdir(path):\n",
    "            # Recursively find all json files (handles test/aeroplane/*.json structure)\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                for f in files:\n",
    "                    if f.endswith('.json'):\n",
    "                        pair_files.append(os.path.join(root, f))\n",
    "            break\n",
    "\n",
    "    if not pair_files:\n",
    "        print(f\"Error: No annotation files found in {search_paths}\")\n",
    "        return {t: 0.0 for t in thresholds}\n",
    "\n",
    "    # Filter for 'aeroplane' only (for faster testing)\n",
    "    pair_files = [f for f in pair_files if 'aeroplane' in f]\n",
    "    print(f\"Evaluating on {len(pair_files)} aeroplane pairs...\")\n",
    "\n",
    "    # Optional: limit to 50 for speed\n",
    "    pair_files = pair_files[:50]\n",
    "\n",
    "    # Transform for DINO\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    correct_kps = {t: 0 for t in thresholds}\n",
    "    total_kps = 0\n",
    "\n",
    "    for pair_path in tqdm(pair_files):\n",
    "        with open(pair_path, 'r') as f:\n",
    "            ann = json.load(f)\n",
    "\n",
    "        # --- FIX: Use 'category' to build correct path ---\n",
    "        category = ann['category']\n",
    "        src_img_path = os.path.join(image_dir, category, ann['src_imname'])\n",
    "        trg_img_path = os.path.join(image_dir, category, ann['trg_imname'])\n",
    "\n",
    "        if not os.path.exists(src_img_path) or not os.path.exists(trg_img_path):\n",
    "            # Debug print only once if missing\n",
    "            if total_kps == 0:\n",
    "                print(f\"Missing Image: {src_img_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load Images\n",
    "        src_pil = Image.open(src_img_path).convert('RGB')\n",
    "        trg_pil = Image.open(trg_img_path).convert('RGB')\n",
    "        src_w, src_h = src_pil.size\n",
    "        trg_w, trg_h = trg_pil.size\n",
    "\n",
    "        # Extract Features\n",
    "        if is_sam:\n",
    "            f_src = extract_sam_features(model, np.array(src_pil))\n",
    "            f_trg = extract_sam_features(model, np.array(trg_pil))\n",
    "        else:\n",
    "            src_tensor = transform(src_pil).unsqueeze(0).to(device)\n",
    "            trg_tensor = transform(trg_pil).unsqueeze(0).to(device)\n",
    "            f_src = extract_dino_features(model, src_tensor)\n",
    "            f_trg = extract_dino_features(model, trg_tensor)\n",
    "\n",
    "        f_src = F.normalize(f_src, dim=1)\n",
    "        f_trg = F.normalize(f_trg, dim=1)\n",
    "        fh, fw = f_src.shape[2], f_src.shape[3]\n",
    "\n",
    "        # Keypoints & BBox\n",
    "        src_kps = ann['src_kps']\n",
    "        trg_kps = ann['trg_kps']\n",
    "        trg_bbox = ann['trg_bndbox']\n",
    "\n",
    "        # PCK Normalization Scale\n",
    "        bbox_w = trg_bbox[2] - trg_bbox[0]\n",
    "        bbox_h = trg_bbox[3] - trg_bbox[1]\n",
    "        norm_factor = max(bbox_w, bbox_h)\n",
    "\n",
    "        kp_indices = range(len(src_kps)) if isinstance(src_kps, list) else src_kps.keys()\n",
    "\n",
    "        for idx in kp_indices:\n",
    "            p_src = src_kps[idx]\n",
    "            p_trg = trg_kps[idx]\n",
    "\n",
    "            if p_src is None or p_trg is None: continue\n",
    "\n",
    "            # 1. Map Source Point -> Feature Grid\n",
    "            if is_sam:\n",
    "                 # SAM: Simple relative mapping\n",
    "                 feat_x = int(p_src[0] / src_w * fw)\n",
    "                 feat_y = int(p_src[1] / src_h * fh)\n",
    "            else:\n",
    "                 # DINO: relative mapping\n",
    "                 feat_x = int(p_src[0] / src_w * fw)\n",
    "                 feat_y = int(p_src[1] / src_h * fh)\n",
    "\n",
    "            feat_x = min(max(feat_x, 0), fw - 1)\n",
    "            feat_y = min(max(feat_y, 0), fh - 1)\n",
    "\n",
    "            # 2. Get Source Descriptor\n",
    "            target_feat = f_src[:, :, feat_y, feat_x] # (1, C)\n",
    "\n",
    "            # 3. Compute Similarity Map\n",
    "            sim = torch.einsum('nc,nchw->nhw', target_feat, f_trg)\n",
    "\n",
    "            # 4. Find Best Match\n",
    "            best_idx = torch.argmax(sim.flatten())\n",
    "            pred_y_idx = best_idx // fw\n",
    "            pred_x_idx = best_idx % fw\n",
    "\n",
    "            # 5. Map back to Target Pixels\n",
    "            pred_x = (pred_x_idx.item() / fw) * trg_w\n",
    "            pred_y = (pred_y_idx.item() / fh) * trg_h\n",
    "\n",
    "            # 6. Evaluate\n",
    "            dist = np.sqrt((pred_x - p_trg[0])**2 + (pred_y - p_trg[1])**2)\n",
    "\n",
    "            total_kps += 1\n",
    "            for t in thresholds:\n",
    "                if dist <= (t * norm_factor):\n",
    "                    correct_kps[t] += 1\n",
    "\n",
    "    return {t: (correct_kps[t] / total_kps) if total_kps > 0 else 0.0 for t in thresholds}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764951198174,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "MUs07YG9PGsm",
    "outputId": "fa8d7fac-00cb-485f-bdd7-d67440d10c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM model moved to CUDA.\n"
     ]
    }
   ],
   "source": [
    "# Move the SAM model to GPU\n",
    "sam.to(device='cuda')\n",
    "sampredictor = SamPredictor(sam) # Re-wrap it just to be safe\n",
    "print(\"SAM model moved to CUDA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45187,
     "status": "ok",
     "timestamp": 1764951244201,
     "user": {
      "displayName": "antonio pio caruso",
      "userId": "01585497553189457278"
     },
     "user_tz": -60
    },
    "id": "4O_dh2btvLRW",
    "outputId": "9b2bcbd1-d8ab-4d97-cfc0-440aa720df38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DINOv2 (Aeroplane)\n",
      "Searching for annotation files...\n",
      "Evaluating on 600 aeroplane pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 PCK: {0.05: 0.21146245059288538, 0.1: 0.5395256916996047, 0.2: 0.7707509881422925}\n",
      "=== Evaluating DINOv3 (Aeroplane) ===\n",
      "Searching for annotation files...\n",
      "Evaluating on 600 aeroplane pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv3 PCK: {0.05: 0.15612648221343872, 0.1: 0.44466403162055335, 0.2: 0.7509881422924901}\n",
      "\n",
      "=== Evaluating SAM (Aeroplane) ===\n",
      "Searching for annotation files...\n",
      "Evaluating on 600 aeroplane pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:40<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM PCK: {0.05: 0.029644268774703556, 0.1: 0.11462450592885376, 0.2: 0.30632411067193677}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Execute ---\n",
    "print(\"Evaluating DINOv2 (Aeroplane)\")\n",
    "dinov2_pck = computePCKatT(dinov2_vitb14, LOCAL_DATA_DIR)\n",
    "print(f\"DINOv2 PCK: {dinov2_pck}\")\n",
    "\n",
    "print(\"\\n=== Evaluating DINOv3 (Aeroplane) ===\")\n",
    "dinov3_pck = computePCKatT(dinov3_vitb16, LOCAL_DATA_DIR)\n",
    "print(f\"DINOv3 PCK: {dinov3_pck}\")\n",
    "\n",
    "print(\"\\n=== Evaluating SAM (Aeroplane) ===\")\n",
    "sam_pck = computePCKatT(sampredictor, LOCAL_DATA_DIR)\n",
    "print(f\"SAM PCK: {sam_pck}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMblDSSmf33hH2oTxuIXeKn",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
